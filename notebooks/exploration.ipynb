{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VetVision-LM â€” Dataset & Model Exploration\n",
    "\n",
    "**Author:** Devarchith Parashara Batchu  \n",
    "**Repository:** https://github.com/devarchith/vetvision-lm\n",
    "\n",
    "This notebook explores:\n",
    "1. Data loading and augmentation pipeline\n",
    "2. Model architecture inspection\n",
    "3. Loss function behaviour\n",
    "4. Smoke-test training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Synthetic Data Pipeline"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.chexpert import SyntheticCheXpertDataset\n",
    "from data.veterinary import SyntheticVetDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "chex_ds = SyntheticCheXpertDataset(num_samples=50)\n",
    "vet_ds = SyntheticVetDataset(num_samples=50)\n",
    "\n",
    "print(f'CheXpert synthetic dataset: {len(chex_ds)} samples')\n",
    "print(f'Vet synthetic dataset: {len(vet_ds)} samples')\n",
    "\n",
    "item = chex_ds[0]\n",
    "print(f'\\nImage shape: {item[\"image\"].shape}')\n",
    "print(f'Labels shape: {item[\"labels\"].shape}')\n",
    "print(f'Text: {item[\"text\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Augmentation Pipeline"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.augmentations import build_train_transform, build_val_transform\n",
    "import numpy as np\n",
    "\n",
    "train_tf = build_train_transform(img_size=224)\n",
    "val_tf = build_val_transform(img_size=224)\n",
    "\n",
    "# Create a synthetic X-ray-like image\n",
    "dummy_xray = Image.fromarray(\n",
    "    np.random.randint(50, 200, (300, 300, 3), dtype=np.uint8)\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(dummy_xray, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "\n",
    "for i, (label, tf) in enumerate([(('Train Aug.', train_tf), ('Val (no aug)', val_tf))[j] for j in range(2)], 1):\n",
    "    t = tf(dummy_xray)\n",
    "    img_show = t.permute(1,2,0).numpy()\n",
    "    img_show = (img_show - img_show.min()) / (img_show.max() - img_show.min() + 1e-8)\n",
    "    axes[i].imshow(img_show)\n",
    "    axes[i].set_title(label)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/augmentation_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Model Architecture"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vetvision import VetVisionLM\n",
    "\n",
    "model = VetVisionLM(\n",
    "    vision_cfg={'name': 'vit_base_patch16_224', 'pretrained': False},\n",
    "    text_cfg={'name': 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext', 'pretrained': False},\n",
    "    species_cfg={'num_species': 2, 'species_embed_dim': 64, 'output_dim': 512},\n",
    "    proj_cfg={'embed_dim': 512, 'hidden_dim': 512, 'vision_input_dim': 768, 'text_input_dim': 768},\n",
    ")\n",
    "\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total parameters:     {total:,}')\n",
    "print(f'Trainable parameters: {trainable:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Smoke-Test Forward Pass"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images = torch.randn(4, 3, 224, 224)\n",
    "    texts = ['Canine thoracic radiograph.'] * 4\n",
    "    species_ids = torch.tensor([0, 1, 0, 1])\n",
    "    \n",
    "    out = model(images=images, texts=texts, species_ids=species_ids)\n",
    "    \n",
    "    print('vision_embed:', out.vision_embed.shape)\n",
    "    print('text_embed:  ', out.text_embed.shape)\n",
    "    print('species_embed:', out.species_embed.shape)\n",
    "    \n",
    "    # Check L2 normalisation\n",
    "    v_norms = out.vision_embed.norm(dim=-1)\n",
    "    print(f'\\nVision embed norms (should be ~1.0): {v_norms.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Loss Function Exploration"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from losses.contrastive import ContrastiveLoss\n",
    "from losses.species_loss import SpeciesContrastiveLoss, CombinedLoss\n",
    "\n",
    "cont_loss = ContrastiveLoss(temperature=0.07)\n",
    "spec_loss = SpeciesContrastiveLoss(temperature=0.07, margin=0.2)\n",
    "combined = CombinedLoss(cont_loss, spec_loss, lambda_species=0.5)\n",
    "\n",
    "# Test with random embeddings\n",
    "B = 8\n",
    "v = F.normalize(torch.randn(B, 512), p=2, dim=-1)\n",
    "t = F.normalize(torch.randn(B, 512), p=2, dim=-1)\n",
    "s = F.normalize(torch.randn(B, 512), p=2, dim=-1)\n",
    "sp = torch.tensor([0,0,0,0,1,1,1,1])\n",
    "\n",
    "result = combined(v, t, s, sp)\n",
    "print('Combined loss:')\n",
    "for k, val in result.items():\n",
    "    print(f'  {k}: {val.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
