model:
  checkpoint: "checkpoints/pretrain/best.pth"
  vision_encoder:
    name: "vit_base_patch16_224"
    pretrained: false
    img_size: 224
    freeze_layers: 8
  text_encoder:
    name: "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
    pretrained: false
    max_length: 128
    freeze_layers: 8
  species_module:
    num_species: 2
    species_embed_dim: 64
    hidden_dim: 512
    output_dim: 512
  projection:
    vision_input_dim: 768
    text_input_dim: 768
    embed_dim: 512
    hidden_dim: 512

loss:
  temperature: 0.07
  lambda_species: 0.5
  margin: 0.2

training:
  batch_size: 32
  learning_rate: 5e-5
  weight_decay: 1e-4
  num_epochs: 30
  warmup_epochs: 3
  lr_schedule: "cosine"
  gradient_clip: 1.0
  num_workers: 8
  pin_memory: true
  mixed_precision: true

data:
  vet_root: "data/vet_dataset"
  manifest_csv: "data/vet_dataset/manifest.csv"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  img_size: 224
  augmentation:
    random_horizontal_flip: 0.5
    random_rotation: 15
    elastic_transform: true
    color_jitter:
      brightness: 0.3
      contrast: 0.3
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

logging:
  log_dir: "logs/finetune"
  checkpoint_dir: "checkpoints/finetune"
  save_every: 5
  log_every: 50
  wandb:
    project: "vetvision-lm"
    entity: null
    enabled: false

hardware:
  device: "cuda"
  num_gpus: 1
  seed: 42
